"""
–°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.

–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ–ø–µ—Ä–∞—Ü–∏–π,
–≤—ã—è–≤–ª–µ–Ω–∏–µ —É–∑–∫–∏—Ö –º–µ—Å—Ç –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é —Ä–µ—Å—É—Ä—Å–æ–≤.
"""

from __future__ import annotations

import asyncio
import logging
import time
from collections import defaultdict
from collections.abc import Callable
from contextlib import asynccontextmanager
from dataclasses import dataclass, field
from typing import Any, TypeVar

from app.core.metrics import observe_latency

logger = logging.getLogger(__name__)

F = TypeVar("F", bound=Callable[..., Any])

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è
_profiling_data: dict[str, list[float]] = defaultdict(list)
_call_counts: dict[str, int] = defaultdict(int)
_concurrent_operations: dict[str, int] = defaultdict(int)
_peak_concurrency: dict[str, int] = defaultdict(int)


@dataclass
class ProfileData:
    """–î–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–∏."""
    name: str
    duration_ms: float
    concurrent_count: int
    timestamp: float
    memory_delta: int = 0
    cpu_percent: float = 0.0
    additional_data: dict[str, Any] = field(default_factory=dict)


@dataclass
class ConcurrencyStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏."""
    current: int
    peak: int
    average: float
    total_calls: int


class PerformanceProfiler:
    """–ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤—â–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
    
    def __init__(self, operation_name: str):
        self.operation_name = operation_name
        self.start_time: float = 0
        self.start_memory: int = 0
    
    def __enter__(self) -> PerformanceProfiler:
        self.start_time = time.perf_counter()
        _concurrent_operations[self.operation_name] += 1
        _peak_concurrency[self.operation_name] = max(
            _peak_concurrency[self.operation_name],
            _concurrent_operations[self.operation_name]
        )
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb) -> None:
        duration_ms = (time.perf_counter() - self.start_time) * 1000
        _concurrent_operations[self.operation_name] -= 1
        _call_counts[self.operation_name] += 1
        _profiling_data[self.operation_name].append(duration_ms)
        
        # –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å–∏—Å—Ç–µ–º–æ–π –º–µ—Ç—Ä–∏–∫
        observe_latency(self.operation_name, duration_ms)
        
        logger.debug(f"Profile: {self.operation_name} took {duration_ms:.2f}ms")


@asynccontextmanager
async def async_profiler(operation_name: str):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤—â–∏–∫."""
    start_time = time.perf_counter()
    _concurrent_operations[operation_name] += 1
    _peak_concurrency[operation_name] = max(
        _peak_concurrency[operation_name],
        _concurrent_operations[operation_name]
    )
    
    try:
        yield
    finally:
        duration_ms = (time.perf_counter() - start_time) * 1000
        _concurrent_operations[operation_name] -= 1
        _call_counts[operation_name] += 1
        _profiling_data[operation_name].append(duration_ms)
        
        # –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å–∏—Å—Ç–µ–º–æ–π –º–µ—Ç—Ä–∏–∫
        observe_latency(operation_name, duration_ms)
        
        logger.debug(f"Async Profile: {operation_name} took {duration_ms:.2f}ms")


def profile_sync(operation_name: str) -> Callable[[F], F]:
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π."""
    def decorator(func: F) -> F:
        def wrapper(*args, **kwargs):
            with PerformanceProfiler(operation_name):
                return func(*args, **kwargs)
        return wrapper  # type: ignore[return-value]
    return decorator


def profile_async(operation_name: str) -> Callable[[F], F]:
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π."""
    def decorator(func: F) -> F:
        async def wrapper(*args, **kwargs):
            async with async_profiler(operation_name):
                return await func(*args, **kwargs)
        return wrapper  # type: ignore[return-value]
    return decorator


def get_operation_stats(operation_name: str) -> dict[str, Any]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –æ–ø–µ—Ä–∞—Ü–∏–∏."""
    durations = _profiling_data.get(operation_name, [])
    if not durations:
        return {
            "operation": operation_name,
            "calls": 0,
            "avg_ms": 0,
            "min_ms": 0,
            "max_ms": 0,
            "total_ms": 0,
            "current_concurrent": 0,
            "peak_concurrent": 0,
        }
    
    return {
        "operation": operation_name,
        "calls": len(durations),
        "avg_ms": sum(durations) / len(durations),
        "min_ms": min(durations),
        "max_ms": max(durations),
        "total_ms": sum(durations),
        "current_concurrent": _concurrent_operations[operation_name],
        "peak_concurrent": _peak_concurrency[operation_name],
    }


def get_concurrency_stats(operation_name: str) -> ConcurrencyStats:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏."""
    durations = _profiling_data.get(operation_name, [])
    total_calls = _call_counts[operation_name]
    
    return ConcurrencyStats(
        current=_concurrent_operations[operation_name],
        peak=_peak_concurrency[operation_name],
        average=sum(durations) / len(durations) if durations else 0,
        total_calls=total_calls,
    )


def get_all_operations_stats() -> dict[str, dict[str, Any]]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≤—Å–µ–º –æ–ø–µ—Ä–∞—Ü–∏—è–º."""
    stats = {}
    all_operations = set(_profiling_data.keys()) | set(_call_counts.keys())
    
    for operation in all_operations:
        stats[operation] = get_operation_stats(operation)
    
    return stats


def get_slow_operations(threshold_ms: float = 1000) -> list[dict[str, Any]]:
    """–ù–∞—Ö–æ–¥–∏—Ç –º–µ–¥–ª–µ–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏."""
    slow_ops = []
    
    for operation, durations in _profiling_data.items():
        if durations:
            avg_duration = sum(durations) / len(durations)
            max_duration = max(durations)
            
            if avg_duration > threshold_ms or max_duration > threshold_ms * 2:
                slow_ops.append({
                    "operation": operation,
                    "avg_ms": avg_duration,
                    "max_ms": max_duration,
                    "calls": len(durations),
                    "severity": "high" if avg_duration > threshold_ms * 2 else "medium",
                })
    
    return sorted(slow_ops, key=lambda x: x["avg_ms"], reverse=True)


def get_high_concurrency_operations(threshold: int = 5) -> list[dict[str, Any]]:
    """–ù–∞—Ö–æ–¥–∏—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –≤—ã—Å–æ–∫–æ–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å—é."""
    high_concurrency = []
    
    for operation, peak in _peak_concurrency.items():
        if peak >= threshold:
            high_concurrency.append({
                "operation": operation,
                "peak_concurrent": peak,
                "current_concurrent": _concurrent_operations[operation],
                "total_calls": _call_counts[operation],
            })
    
    return sorted(high_concurrency, key=lambda x: x["peak_concurrent"], reverse=True)


def reset_profiling_data() -> None:
    """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è."""
    _profiling_data.clear()
    _call_counts.clear()
    _concurrent_operations.clear()
    _peak_concurrency.clear()
    logger.info("Profiling data reset")


def get_performance_summary() -> dict[str, Any]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–≤–æ–¥–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
    all_stats = get_all_operations_stats()
    slow_ops = get_slow_operations()
    high_concurrency = get_high_concurrency_operations()
    
    total_operations = sum(stats["calls"] for stats in all_stats.values())
    total_time_ms = sum(stats["total_ms"] for stats in all_stats.values())
    
    return {
        "summary": {
            "total_operations": total_operations,
            "total_time_ms": total_time_ms,
            "average_operation_ms": total_time_ms / total_operations if total_operations > 0 else 0,
            "unique_operations": len(all_stats),
        },
        "slow_operations": slow_ops,
        "high_concurrency_operations": high_concurrency,
        "top_operations_by_time": sorted(
            all_stats.values(), 
            key=lambda x: x["total_ms"], 
            reverse=True
        )[:10],
        "top_operations_by_calls": sorted(
            all_stats.values(), 
            key=lambda x: x["calls"], 
            reverse=True
        )[:10],
    }


# =============== ASYNC BENCHMARKING ===============


async def benchmark_async_vs_sync(
    operation_name: str,
    async_func: Callable[[], Any],
    sync_func: Callable[[], Any],
    iterations: int = 10,
) -> dict[str, Any]:
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å async vs sync –æ–ø–µ—Ä–∞—Ü–∏–π.
    
    Args:
        operation_name: –ù–∞–∑–≤–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        async_func: –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        sync_func: –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        iterations: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π
        
    Returns:
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    logger.info(f"Benchmarking {operation_name}: async vs sync ({iterations} iterations)")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º async –≤–µ—Ä—Å–∏—é (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
    async_start = time.perf_counter()
    async_tasks = [async_func() for _ in range(iterations)]
    async_results = await asyncio.gather(*async_tasks, return_exceptions=True)
    async_duration = time.perf_counter() - async_start
    
    async_errors = sum(1 for r in async_results if isinstance(r, Exception))
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º sync –≤–µ—Ä—Å–∏—é —á–µ—Ä–µ–∑ executor (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ)
    sync_start = time.perf_counter()
    sync_results = []
    for _ in range(iterations):
        try:
            result = await asyncio.get_event_loop().run_in_executor(None, sync_func)
            sync_results.append(result)
        except Exception as e:
            sync_results.append(e)
    sync_duration = time.perf_counter() - sync_start
    
    sync_errors = sum(1 for r in sync_results if isinstance(r, Exception))
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    speedup = sync_duration / async_duration if async_duration > 0 else float('inf')
    
    stats = {
        "operation": operation_name,
        "iterations": iterations,
        "async": {
            "duration_ms": async_duration * 1000,
            "avg_per_op_ms": (async_duration * 1000) / iterations,
            "errors": async_errors,
            "success_rate": (iterations - async_errors) / iterations,
        },
        "sync": {
            "duration_ms": sync_duration * 1000,
            "avg_per_op_ms": (sync_duration * 1000) / iterations,
            "errors": sync_errors,
            "success_rate": (iterations - sync_errors) / iterations,
        },
        "comparison": {
            "speedup": speedup,
            "async_faster": speedup > 1.0,
            "time_saved_ms": (sync_duration - async_duration) * 1000,
            "efficiency_gain": ((sync_duration - async_duration) / sync_duration) * 100 if sync_duration > 0 else 0,
        }
    }
    
    logger.info(
        f"Benchmark {operation_name}: "
        f"async {stats['async']['duration_ms']:.1f}ms vs sync {stats['sync']['duration_ms']:.1f}ms "
        f"(speedup: {speedup:.1f}x)"
    )
    
    return stats


# =============== RESOURCE MONITORING ===============


def get_memory_usage() -> dict[str, Any]:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –ø–∞–º—è—Ç–∏."""
    try:
        import psutil
        process = psutil.Process()
        memory_info = process.memory_info()
        
        return {
            "rss_mb": memory_info.rss / 1024 / 1024,  # Resident Set Size
            "vms_mb": memory_info.vms / 1024 / 1024,  # Virtual Memory Size
            "percent": process.memory_percent(),
            "available": True,
        }
    except ImportError:
        return {"available": False, "error": "psutil –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"}
    except Exception as e:
        return {"available": False, "error": str(e)}


def get_cpu_usage() -> dict[str, Any]:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ CPU."""
    try:
        import psutil
        process = psutil.Process()
        
        return {
            "percent": process.cpu_percent(),
            "num_threads": process.num_threads(),
            "available": True,
        }
    except ImportError:
        return {"available": False, "error": "psutil –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"}
    except Exception as e:
        return {"available": False, "error": str(e)}


def get_system_resources() -> dict[str, Any]:
    """–ü–æ–ª—É—á–∞–µ—Ç –æ–±—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–∞—Ö."""
    return {
        "memory": get_memory_usage(),
        "cpu": get_cpu_usage(),
        "timestamp": time.time(),
    }


# =============== BOTTLENECK DETECTION ===============


def detect_bottlenecks(min_calls: int = 10) -> dict[str, Any]:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã—è–≤–ª—è–µ—Ç —É–∑–∫–∏–µ –º–µ—Å—Ç–∞ –≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
    
    Args:
        min_calls: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–∑–æ–≤–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        
    Returns:
        –ê–Ω–∞–ª–∏–∑ —É–∑–∫–∏—Ö –º–µ—Å—Ç —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
    """
    bottlenecks = {
        "slow_operations": [],
        "high_concurrency": [],
        "frequent_operations": [],
        "recommendations": [],
    }
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–¥–ª–µ–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
    for operation, durations in _profiling_data.items():
        if len(durations) < min_calls:
            continue
            
        avg_duration = sum(durations) / len(durations)
        max_duration = max(durations)
        p95_duration = sorted(durations)[int(len(durations) * 0.95)]
        
        # –ú–µ–¥–ª–µ–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ (>1s —Å—Ä–µ–¥–Ω–µ–µ –∏–ª–∏ >5s –º–∞–∫—Å–∏–º—É–º)
        if avg_duration > 1000 or max_duration > 5000:
            bottlenecks["slow_operations"].append({
                "operation": operation,
                "avg_ms": avg_duration,
                "max_ms": max_duration,
                "p95_ms": p95_duration,
                "calls": len(durations),
                "severity": "critical" if avg_duration > 2000 else "warning",
            })
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—ã—Å–æ–∫—É—é –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å
    for operation, peak in _peak_concurrency.items():
        if peak >= 10:  # –ë–æ–ª–µ–µ 10 –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
            bottlenecks["high_concurrency"].append({
                "operation": operation,
                "peak_concurrent": peak,
                "total_calls": _call_counts[operation],
                "avg_concurrent": peak / _call_counts[operation] if _call_counts[operation] > 0 else 0,
            })
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–∞—Å—Ç—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
    frequent_ops = sorted(_call_counts.items(), key=lambda x: x[1], reverse=True)[:5]
    for operation, calls in frequent_ops:
        if calls >= min_calls:
            durations = _profiling_data.get(operation, [])
            avg_duration = sum(durations) / len(durations) if durations else 0
            
            bottlenecks["frequent_operations"].append({
                "operation": operation,
                "calls": calls,
                "avg_ms": avg_duration,
                "total_time_ms": sum(durations),
            })
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    recommendations = []
    
    if bottlenecks["slow_operations"]:
        recommendations.append("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–µ–¥–ª–µ–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏: –¥–æ–±–∞–≤–∏—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–ª–∏ —É–º–µ–Ω—å—à–∏—Ç—å timeout'—ã")
    
    if bottlenecks["high_concurrency"]:
        recommendations.append("–î–æ–±–∞–≤–∏—Ç—å —Å–µ–º–∞—Ñ–æ—Ä—ã –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –≤ –≤—ã—Å–æ–∫–æ–Ω–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏—è—Ö")
    
    if len(bottlenecks["frequent_operations"]) > 3:
        recommendations.append("–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —á–∞—Å—Ç–æ –≤—ã–∑—ã–≤–∞–µ–º—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π")
    
    bottlenecks["recommendations"] = recommendations
    
    return bottlenecks


def generate_performance_report() -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ —á–∏—Ç–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ."""
    summary = get_performance_summary()
    bottlenecks = detect_bottlenecks()
    resources = get_system_resources()
    
    report = []
    report.append("üìä –û–¢–ß–ï–¢ –û –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò")
    report.append("=" * 50)
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_ops = summary["summary"]["total_operations"]
    total_time = summary["summary"]["total_time_ms"]
    avg_time = summary["summary"]["average_operation_ms"]
    
    report.append(f"üî¢ –í—Å–µ–≥–æ –æ–ø–µ—Ä–∞—Ü–∏–π: {total_ops}")
    report.append(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.1f}ms")
    report.append(f"üìà –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {avg_time:.1f}ms/–æ–ø–µ—Ä–∞—Ü–∏—è")
    report.append("")
    
    # –¢–æ–ø –æ–ø–µ—Ä–∞—Ü–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    if summary["top_operations_by_time"]:
        report.append("üêå –¢–û–ü –ú–ï–î–õ–ï–ù–ù–´–• –û–ü–ï–†–ê–¶–ò–ô:")
        for i, op in enumerate(summary["top_operations_by_time"][:5], 1):
            report.append(f"{i}. {op['operation']}: {op['avg_ms']:.1f}ms (–≤—ã–∑–æ–≤–æ–≤: {op['calls']})")
        report.append("")
    
    # –£–∑–∫–∏–µ –º–µ—Å—Ç–∞
    if bottlenecks["slow_operations"]:
        report.append("‚ö†Ô∏è –£–ó–ö–ò–ï –ú–ï–°–¢–ê:")
        for bottleneck in bottlenecks["slow_operations"][:3]:
            severity = "üî¥" if bottleneck["severity"] == "critical" else "üü°"
            report.append(f"{severity} {bottleneck['operation']}: {bottleneck['avg_ms']:.1f}ms —Å—Ä–µ–¥–Ω–µ–µ")
        report.append("")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    if bottlenecks["recommendations"]:
        report.append("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        for i, rec in enumerate(bottlenecks["recommendations"], 1):
            report.append(f"{i}. {rec}")
        report.append("")
    
    # –†–µ—Å—É—Ä—Å—ã —Å–∏—Å—Ç–µ–º—ã
    if resources["memory"]["available"]:
        memory_mb = resources["memory"]["rss_mb"]
        memory_percent = resources["memory"]["percent"]
        report.append(f"üíæ –ü–∞–º—è—Ç—å: {memory_mb:.1f}MB ({memory_percent:.1f}%)")
    
    if resources["cpu"]["available"]:
        cpu_percent = resources["cpu"]["percent"]
        threads = resources["cpu"]["num_threads"]
        report.append(f"üñ•Ô∏è CPU: {cpu_percent:.1f}% ({threads} –ø–æ—Ç–æ–∫–æ–≤)")
    
    return "\n".join(report)
