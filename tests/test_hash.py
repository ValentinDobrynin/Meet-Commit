"""
–¢–µ—Å—Ç—ã –¥–ª—è –º–æ–¥—É–ª—è —Ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤.
"""

from app.core.hash import (
    _normalize_for_hash,
    compute_raw_hash,
    debug_normalization,
)


class TestNormalization:
    """–¢–µ—Å—Ç—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞."""

    def test_normalize_basic_text(self):
        """–¢–µ—Å—Ç –±–∞–∑–æ–≤–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏."""
        text = "–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?"
        result = _normalize_for_hash(text)
        assert result == "–ø—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?"

    def test_normalize_removes_timestamps(self):
        """–¢–µ—Å—Ç —É–¥–∞–ª–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫."""
        text = "–í–∞–ª–µ–Ω—Ç–∏–Ω 12:30: –ü—Ä–∏–≤–µ—Ç! –í—Å—Ç—Ä–µ—á–∞ –≤ 15:45."
        result = _normalize_for_hash(text)
        assert "12:30" not in result
        assert "15:45" not in result
        assert "–ø—Ä–∏–≤–µ—Ç! –≤—Å—Ç—Ä–µ—á–∞ –≤" in result

    def test_normalize_removes_speaker_labels(self):
        """–¢–µ—Å—Ç —É–¥–∞–ª–µ–Ω–∏—è –º–µ—Ç–æ–∫ —Å–ø–∏–∫–µ—Ä–æ–≤."""
        text = "Speaker: –í–∞–ª–µ–Ω—Ç–∏–Ω –≥–æ–≤–æ—Ä–∏—Ç\n–°–∞—à–∞: –û—Ç–≤–µ—á–∞–µ—Ç\n–û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç"
        result = _normalize_for_hash(text)
        assert "speaker:" not in result.lower()
        assert "—Å–∞—à–∞:" not in result.lower()
        assert "–æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç" in result

    def test_normalize_handles_whitespace(self):
        """–¢–µ—Å—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–±–µ–ª–æ–≤."""
        text = "–ú–Ω–æ–≥–æ    –ø—Ä–æ–±–µ–ª–æ–≤\n\n\n–∏   –ø–µ—Ä–µ–Ω–æ—Å–æ–≤"
        result = _normalize_for_hash(text)
        assert "–º–Ω–æ–≥–æ –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤" in result

    def test_normalize_empty_text(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—É—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""
        assert _normalize_for_hash("") == ""
        assert _normalize_for_hash("   ") == ""


class TestHashComputation:
    """–¢–µ—Å—Ç—ã –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ö—ç—à–µ–π."""

    def test_compute_raw_hash_stable(self):
        """–¢–µ—Å—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Ö—ç—à–∞."""
        text = "–¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –≤—Å—Ç—Ä–µ—á–∏"
        hash1 = compute_raw_hash(text)
        hash2 = compute_raw_hash(text)
        assert hash1 == hash2
        assert len(hash1) == 64  # SHA-256

    def test_compute_raw_hash_different_timestamps(self):
        """–¢–µ—Å—Ç —á—Ç–æ —Ä–∞–∑–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –¥–∞—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ö—ç—à."""
        text1 = "–í–∞–ª–µ–Ω—Ç–∏–Ω 12:30: –û–±—Å—É–∂–¥–∞–µ–º –ø—Ä–æ–µ–∫—Ç"
        text2 = "–í–∞–ª–µ–Ω—Ç–∏–Ω 15:45: –û–±—Å—É–∂–¥–∞–µ–º –ø—Ä–æ–µ–∫—Ç"
        assert compute_raw_hash(text1) == compute_raw_hash(text2)

    def test_compute_raw_hash_different_speakers(self):
        """–¢–µ—Å—Ç —á—Ç–æ —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–∫–∏ —Å–ø–∏–∫–µ—Ä–æ–≤ –¥–∞—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ö—ç—à."""
        text1 = "Speaker: –í–∞–ª–µ–Ω—Ç–∏–Ω\n–û–±—Å—É–∂–¥–∞–µ–º –ø—Ä–æ–µ–∫—Ç"
        text2 = "–°–ø–∏–∫–µ—Ä: –í–∞–ª–µ–Ω—Ç–∏–Ω\n–û–±—Å—É–∂–¥–∞–µ–º –ø—Ä–æ–µ–∫—Ç"
        assert compute_raw_hash(text1) == compute_raw_hash(text2)


class TestEdgeCases:
    """–¢–µ—Å—Ç—ã –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤."""

    def test_unicode_normalization(self):
        """–¢–µ—Å—Ç Unicode –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏."""
        # –†–∞–∑–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –∑–∞–ø–∏—Å–∏ –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
        text1 = "caf√©"  # √© –∫–∞–∫ –æ–¥–∏–Ω —Å–∏–º–≤–æ–ª
        text2 = "cafe\u0301"  # √© –∫–∞–∫ e + combining accent
        assert compute_raw_hash(text1) == compute_raw_hash(text2)

    def test_emoji_removal(self):
        """–¢–µ—Å—Ç —É–¥–∞–ª–µ–Ω–∏—è —ç–º–æ–¥–∑–∏."""
        text1 = "–ü—Ä–∏–≤–µ—Ç! üòä –ö–∞–∫ –¥–µ–ª–∞? üöÄ"
        text2 = "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?"
        assert compute_raw_hash(text1) == compute_raw_hash(text2)

    def test_case_insensitive(self):
        """–¢–µ—Å—Ç –Ω–µ—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫ —Ä–µ–≥–∏—Å—Ç—Ä—É."""
        text1 = "–ü–†–ò–í–ï–¢ –ö–ê–ö –î–ï–õ–ê"
        text2 = "–ø—Ä–∏–≤–µ—Ç –∫–∞–∫ –¥–µ–ª–∞"
        assert compute_raw_hash(text1) == compute_raw_hash(text2)

    def test_complex_speaker_patterns(self):
        """–¢–µ—Å—Ç —Å–ª–æ–∂–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å–ø–∏–∫–µ—Ä–æ–≤."""
        text1 = """
        –í–∞–ª–µ–Ω—Ç–∏–Ω: –ù–∞—á–∏–Ω–∞–µ–º –≤—Å—Ç—Ä–µ—á—É
        –£—á–∞—Å—Ç–Ω–∏–∫ - –°–∞—à–∞: –ì–æ—Ç–æ–≤
        –ì–æ–≤–æ—Ä—è—â–∏–π: –ò–≤–∞–Ω –æ—Ç–≤–µ—á–∞–µ—Ç
        –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –º–µ—Ç–æ–∫
        """

        result = _normalize_for_hash(text1)
        assert "–≤–∞–ª–µ–Ω—Ç–∏–Ω:" not in result
        assert "—É—á–∞—Å—Ç–Ω–∏–∫" not in result
        assert "–≥–æ–≤–æ—Ä—è—â–∏–π:" not in result
        assert "–æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –º–µ—Ç–æ–∫" in result


class TestDebugFeatures:
    """–¢–µ—Å—Ç—ã –æ—Ç–ª–∞–¥–æ—á–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π."""

    def test_debug_normalization(self):
        """–¢–µ—Å—Ç –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏."""
        text = "–í–∞–ª–µ–Ω—Ç–∏–Ω 12:30: –ü—Ä–∏–≤–µ—Ç! üòä"
        debug_info = debug_normalization(text)

        assert "original" in debug_info
        assert "unicode_normalized" in debug_info
        assert "no_timestamps" in debug_info
        assert "no_speakers" in debug_info
        assert "no_emoji" in debug_info
        assert "final_normalized" in debug_info
        assert "hash" in debug_info

        assert debug_info["original"] == text
        assert "12:30" not in debug_info["no_timestamps"]
        assert "üòä" not in debug_info["no_emoji"]
        assert len(debug_info["hash"]) == 64


class TestCaching:
    """–¢–µ—Å—Ç—ã –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è."""

    def test_hash_caching(self):
        """–¢–µ—Å—Ç —á—Ç–æ —Ö—ç—à –∫—ç—à–∏—Ä—É–µ—Ç—Å—è (LRU cache)."""
        text = "–¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è"

        # –ü–µ—Ä–≤—ã–π –≤—ã–∑–æ–≤
        hash1 = compute_raw_hash(text)

        # –í—Ç–æ—Ä–æ–π –≤—ã–∑–æ–≤ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–∑ –∫—ç—à–∞
        hash2 = compute_raw_hash(text)

        assert hash1 == hash2
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∫—ç—à–∏—Ä—É–µ—Ç—Å—è
        assert hasattr(compute_raw_hash, "cache_info")


class TestRealWorldScenarios:
    """–¢–µ—Å—Ç—ã —Ä–µ–∞–ª—å–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤."""

    def test_meeting_transcript_variations(self):
        """–¢–µ—Å—Ç –≤–∞—Ä–∏–∞—Ü–∏–π –æ–¥–Ω–æ–≥–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞."""
        base_transcript = """
        –û–±—Å—É–∂–¥–µ–Ω–∏–µ –ø–ª–∞–Ω–æ–≤ –Ω–∞ –∫–≤–∞—Ä—Ç–∞–ª.
        –ù—É–∂–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –æ—Ç—á–µ—Ç –ø–æ IFRS.
        –°–∞—à–∞ –∑–∞–π–º–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑–æ–º.
        """

        # –í–∞—Ä–∏–∞—Ü–∏—è 1: —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
        var1 = """
        12:30 –û–±—Å—É–∂–¥–µ–Ω–∏–µ –ø–ª–∞–Ω–æ–≤ –Ω–∞ –∫–≤–∞—Ä—Ç–∞–ª.
        12:35 –ù—É–∂–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –æ—Ç—á–µ—Ç –ø–æ IFRS.
        12:40 –°–∞—à–∞ –∑–∞–π–º–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑–æ–º.
        """

        # –í–∞—Ä–∏–∞—Ü–∏—è 2: –ø—Ä–æ—Å—Ç—ã–µ –º–µ—Ç–∫–∏ —Å–ø–∏–∫–µ—Ä–æ–≤
        var2 = """
        –í–∞–ª–µ–Ω—Ç–∏–Ω: –û–±—Å—É–∂–¥–µ–Ω–∏–µ –ø–ª–∞–Ω–æ–≤ –Ω–∞ –∫–≤–∞—Ä—Ç–∞–ª.
        Speaker: –ù—É–∂–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –æ—Ç—á–µ—Ç –ø–æ IFRS.
        –°–∞—à–∞: –∑–∞–π–º–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑–æ–º.
        """

        # –ë–∞–∑–æ–≤—ã–π –∏ –ø–µ—Ä–≤–∞—è –≤–∞—Ä–∏–∞—Ü–∏—è –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å (—É–±–∏—Ä–∞—é—Ç—Å—è timestamps)
        hash_base = compute_raw_hash(base_transcript)
        hash_var1 = compute_raw_hash(var1)
        hash_var2 = compute_raw_hash(var2)

        assert hash_base == hash_var1  # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ —É–±–∏—Ä–∞—é—Ç—Å—è
        assert hash_var2 != hash_base  # –°–ø–∏–∫–µ—Ä—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è, –Ω–æ –º–æ–≥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ

    def test_filename_independence(self):
        """–¢–µ—Å—Ç —á—Ç–æ —Ö—ç—à –Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞."""
        transcript = "–û–±—Å—É–∂–¥–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ –õ–∞–≤–∫–∞"

        # –•—ç—à –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        hash1 = compute_raw_hash(transcript)
        hash2 = compute_raw_hash(transcript)

        assert hash1 == hash2

    def test_minor_text_differences(self):
        """–¢–µ—Å—Ç —á—Ç–æ –º–∏–Ω–æ—Ä–Ω—ã–µ –æ—Ç–ª–∏—á–∏—è –¥–∞—é—Ç —Ä–∞–∑–Ω—ã–µ —Ö—ç—à–∏."""
        text1 = "–û–±—Å—É–∂–¥–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ –õ–∞–≤–∫–∞"
        text2 = "–û–±—Å—É–∂–¥–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ –ú–∞—Ä–∫–µ—Ç"  # –†–∞–∑–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

        assert compute_raw_hash(text1) != compute_raw_hash(text2)

    def test_lavka_declensions(self):
        """–¢–µ—Å—Ç —á—Ç–æ —Ä–∞–∑–Ω—ã–µ —Å–∫–ª–æ–Ω–µ–Ω–∏—è –¥–∞—é—Ç —Ä–∞–∑–Ω—ã–µ —Ö—ç—à–∏ (—ç—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ)."""
        text1 = "–û–±—Å—É–∂–¥–µ–Ω–∏–µ –õ–∞–≤–∫–∏"
        text2 = "–û–±—Å—É–∂–¥–µ–Ω–∏–µ –õ–∞–≤–∫–µ"

        # –†–∞–∑–Ω—ã–µ —Å–∫–ª–æ–Ω–µ–Ω–∏—è = —Ä–∞–∑–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç = —Ä–∞–∑–Ω—ã–µ —Ö—ç—à–∏
        assert compute_raw_hash(text1) != compute_raw_hash(text2)
