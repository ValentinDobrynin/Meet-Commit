"""
Тесты для системы очистки Review Queue app/core/review_cleanup.py

Покрывает:
- Автоматическое архивирование старых записей
- Обнаружение дубликатов по содержимому
- Массовые операции очистки
- Валидацию параметров и обработку ошибок
- Метрики производительности
"""

from datetime import UTC, datetime, timedelta
from unittest.mock import patch

from app.core.review_cleanup import (
    CleanupStats,
    auto_archive_old_reviews,
    calculate_text_similarity,
    cleanup_by_status,
    comprehensive_cleanup,
    estimate_cleanup_time,
    find_duplicate_reviews,
    normalize_text_for_comparison,
    text_fingerprint,
    validate_cleanup_params,
)


class TestCleanupStats:
    """Тесты класса статистики очистки."""

    def test_stats_initialization(self):
        """Тест инициализации статистики."""
        stats = CleanupStats()

        assert stats.scanned == 0
        assert stats.archived == 0
        assert stats.duplicates_found == 0
        assert stats.errors == 0
        assert stats.processing_time_s == 0.0
        assert isinstance(stats.duplicate_pairs, list)

    def test_stats_as_dict(self):
        """Тест преобразования статистики в словарь."""
        stats = CleanupStats()
        stats.scanned = 10
        stats.archived = 5
        stats.duplicates_found = 2
        stats.duplicate_pairs = [("id1", "id2", 0.95)]

        result = stats.as_dict()

        assert isinstance(result, dict)
        assert result["summary"]["scanned"] == 10
        assert result["summary"]["archived"] == 5
        assert result["summary"]["duplicates_found"] == 2
        assert len(result["duplicates"]) == 1
        assert result["duplicates"][0]["similarity"] == 0.95


class TestTextProcessing:
    """Тесты обработки текста для сравнения."""

    def test_normalize_text_for_comparison(self):
        """Тест нормализации текста."""
        # Базовая нормализация
        result = normalize_text_for_comparison("  Подготовить ОТЧЕТ!  ")
        assert result == "подготовить отчет"

        # Удаление пунктуации
        result = normalize_text_for_comparison("Задача: подготовить отчет, проверить данные.")
        assert result == "задача подготовить отчет проверить данные"

        # Пустой текст
        assert normalize_text_for_comparison("") == ""
        assert normalize_text_for_comparison("   ") == ""

    def test_text_fingerprint(self):
        """Тест создания fingerprint текста."""
        # Одинаковые тексты должны давать одинаковые fingerprints
        fp1 = text_fingerprint("подготовить отчет")
        fp2 = text_fingerprint("Подготовить ОТЧЕТ!")
        assert fp1 == fp2

        # Разные тексты должны давать разные fingerprints
        fp3 = text_fingerprint("проверить данные")
        assert fp1 != fp3

        # Пустой текст
        fp_empty = text_fingerprint("")
        assert fp_empty == "0" * 16

        # Длина fingerprint
        assert len(fp1) == 16

    def test_calculate_text_similarity(self):
        """Тест вычисления похожести текстов."""
        # Идентичные тексты
        sim = calculate_text_similarity("подготовить отчет", "подготовить отчет")
        assert sim == 1.0

        # Очень похожие тексты
        sim = calculate_text_similarity("подготовить отчет", "подготовить отчёт")
        assert sim > 0.6  # Алгоритм учитывает различия в символах

        # Частично похожие тексты
        sim = calculate_text_similarity("подготовить отчет", "подготовить презентацию")
        assert 0.3 < sim < 0.8

        # Разные тексты
        sim = calculate_text_similarity("подготовить отчет", "проверить данные")
        assert sim < 0.5

        # Пустые тексты
        assert calculate_text_similarity("", "") == 0.0
        assert calculate_text_similarity("текст", "") == 0.0


class TestParameterValidation:
    """Тесты валидации параметров."""

    def test_valid_modes(self):
        """Тест валидных режимов очистки."""
        valid_modes = ["old", "dups", "status", "all", "dry-run"]

        for mode in valid_modes:
            is_valid, error_msg = validate_cleanup_params(mode)
            assert is_valid, f"Mode {mode} should be valid"
            assert error_msg == ""

    def test_invalid_modes(self):
        """Тест невалидных режимов."""
        invalid_modes = ["invalid", "", "clean", "remove"]

        for mode in invalid_modes:
            is_valid, error_msg = validate_cleanup_params(mode)
            assert not is_valid, f"Mode {mode} should be invalid"
            assert "Неверный режим" in error_msg

    def test_days_validation(self):
        """Тест валидации количества дней."""
        # Валидные значения
        valid_days = [1, 7, 14, 30, 365]
        for days in valid_days:
            is_valid, error_msg = validate_cleanup_params("old", days)
            assert is_valid, f"Days {days} should be valid"

        # Невалидные значения
        invalid_days = [0, -1, 366, "abc"]
        for days in invalid_days:
            is_valid, error_msg = validate_cleanup_params("old", days)
            assert not is_valid, f"Days {days} should be invalid"

    def test_threshold_validation(self):
        """Тест валидации порога похожести."""
        # Валидные значения
        valid_thresholds = [0.0, 0.5, 0.85, 1.0]
        for threshold in valid_thresholds:
            is_valid, error_msg = validate_cleanup_params("dups", None, threshold)
            assert is_valid, f"Threshold {threshold} should be valid"

        # Невалидные значения
        invalid_thresholds = [-0.1, 1.1, "abc"]
        for threshold in invalid_thresholds:
            is_valid, error_msg = validate_cleanup_params("dups", None, threshold)
            assert not is_valid, f"Threshold {threshold} should be invalid"


class TestTimeEstimation:
    """Тесты оценки времени выполнения."""

    def test_different_modes_estimation(self):
        """Тест оценки для разных режимов."""
        modes = ["old", "dups", "status", "all"]

        for mode in modes:
            estimate = estimate_cleanup_time(mode, 100)

            assert isinstance(estimate, dict)
            assert "estimated_reviews" in estimate
            assert "estimated_time_seconds" in estimate
            assert "complexity" in estimate

            assert estimate["estimated_reviews"] == 100
            assert estimate["estimated_time_seconds"] > 0

    def test_complexity_differences(self):
        """Тест различий в сложности алгоритмов."""
        # Дубликаты должны иметь квадратичную сложность
        dups_estimate = estimate_cleanup_time("dups", 100)
        old_estimate = estimate_cleanup_time("old", 100)

        assert dups_estimate["complexity"] == "O(n²)"
        assert old_estimate["complexity"] == "O(n)"

        # Дубликаты должны занимать больше времени для больших объемов
        dups_large = estimate_cleanup_time("dups", 1000)
        old_large = estimate_cleanup_time("old", 1000)
        assert dups_large["estimated_time_seconds"] > old_large["estimated_time_seconds"]


class TestAutoArchiveOldReviews:
    """Тесты автоматического архивирования старых записей."""

    @patch("app.gateways.notion_review.fetch_all_reviews")
    @patch("app.gateways.notion_review.bulk_update_status")
    def test_archive_old_resolved_records(self, mock_bulk_update, mock_fetch):
        """Тест архивирования старых resolved записей."""
        # Мокаем данные - старая resolved запись
        old_date = (datetime.now(UTC) - timedelta(days=20)).isoformat()

        mock_fetch.return_value = [
            {
                "id": "old-review-1",
                "status": "resolved",
                "last_edited_time": old_date,
                "text": "старая задача",
            }
        ]
        mock_bulk_update.return_value = {"updated": 1, "errors": 0}

        # Выполняем архивирование
        stats = auto_archive_old_reviews(days_threshold=14, dry_run=False)

        # Проверяем результат
        assert stats.scanned == 1
        assert stats.archived == 1
        assert stats.old_resolved == 1
        assert stats.errors == 0

        # Проверяем что bulk_update вызывался
        mock_bulk_update.assert_called_once_with(["old-review-1"], "archived")

    @patch("app.gateways.notion_review.fetch_all_reviews")
    def test_archive_dry_run_mode(self, mock_fetch):
        """Тест dry-run режима архивирования."""
        old_date = (datetime.now(UTC) - timedelta(days=20)).isoformat()

        mock_fetch.return_value = [
            {
                "id": "old-review-1",
                "status": "resolved",
                "last_edited_time": old_date,
                "text": "старая задача",
            }
        ]

        # Выполняем в dry-run режиме
        stats = auto_archive_old_reviews(days_threshold=14, dry_run=True)

        # В dry-run режиме должно считать как архивированные, но не обновлять
        assert stats.scanned == 1
        assert stats.archived == 1  # Считается как архивированные в dry-run
        assert stats.old_resolved == 1

    @patch("app.gateways.notion_review.fetch_all_reviews")
    def test_archive_skip_recent_records(self, mock_fetch):
        """Тест пропуска свежих записей."""
        recent_date = (datetime.now(UTC) - timedelta(days=5)).isoformat()

        mock_fetch.return_value = [
            {
                "id": "recent-review-1",
                "status": "resolved",
                "last_edited_time": recent_date,
                "text": "свежая задача",
            }
        ]

        # Выполняем архивирование с порогом 14 дней
        stats = auto_archive_old_reviews(days_threshold=14, dry_run=True)

        # Свежие записи не должны архивироваться
        assert stats.scanned == 1
        assert stats.archived == 0
        assert stats.old_resolved == 0

    @patch("app.gateways.notion_review.fetch_all_reviews")
    def test_archive_skip_open_statuses(self, mock_fetch):
        """Тест пропуска открытых статусов."""
        old_date = (datetime.now(UTC) - timedelta(days=20)).isoformat()

        mock_fetch.return_value = [
            {
                "id": "pending-review-1",
                "status": "pending",  # Открытый статус
                "last_edited_time": old_date,
                "text": "активная задача",
            }
        ]

        # Выполняем архивирование
        stats = auto_archive_old_reviews(days_threshold=14, dry_run=True)

        # Открытые статусы не должны архивироваться
        assert stats.scanned == 1
        assert stats.archived == 0


class TestDuplicateDetection:
    """Тесты обнаружения дубликатов."""

    @patch("app.gateways.notion_review.fetch_all_reviews")
    def test_find_exact_duplicates(self, mock_fetch):
        """Тест поиска точных дубликатов."""
        mock_fetch.return_value = [
            {"id": "review-1", "text": "подготовить отчет", "status": "pending"},
            {"id": "review-2", "text": "подготовить отчет", "status": "pending"},
        ]

        stats = find_duplicate_reviews(similarity_threshold=0.85)

        assert stats.scanned == 2
        assert stats.duplicates_found == 1
        assert len(stats.duplicate_pairs) == 1
        assert stats.duplicate_pairs[0][2] == 1.0  # Точное совпадение

    @patch("app.gateways.notion_review.fetch_all_reviews")
    def test_find_similar_duplicates(self, mock_fetch):
        """Тест поиска похожих дубликатов."""
        mock_fetch.return_value = [
            {"id": "review-1", "text": "подготовить отчет по продажам", "status": "pending"},
            {
                "id": "review-2",
                "text": "подготовить отчёт по продажам",
                "status": "pending",
            },  # Опечатка
            {"id": "review-3", "text": "проверить данные", "status": "pending"},  # Разный текст
        ]

        stats = find_duplicate_reviews(similarity_threshold=0.85)

        assert stats.scanned == 3
        # similarity_checks зависит от fingerprints - если тексты очень разные, проверок может не быть\n        assert stats.similarity_checks >= 0  # Может быть 0 если нет похожих fingerprints
        # Должен найти дубликат между review-1 и review-2
        assert stats.duplicates_found >= 1

    @patch("app.gateways.notion_review.fetch_all_reviews")
    def test_no_duplicates_found(self, mock_fetch):
        """Тест когда дубликаты не найдены."""
        mock_fetch.return_value = [
            {"id": "review-1", "text": "подготовить отчет", "status": "pending"},
            {"id": "review-2", "text": "проверить данные", "status": "pending"},
            {"id": "review-3", "text": "создать презентацию", "status": "pending"},
        ]

        stats = find_duplicate_reviews(similarity_threshold=0.85)

        assert stats.scanned == 3
        assert stats.duplicates_found == 0
        assert len(stats.duplicate_pairs) == 0

    @patch("app.gateways.notion_review.fetch_all_reviews")
    def test_empty_review_queue(self, mock_fetch):
        """Тест пустой очереди."""
        mock_fetch.return_value = []

        stats = find_duplicate_reviews()

        assert stats.scanned == 0
        assert stats.duplicates_found == 0
        assert stats.similarity_checks == 0


class TestStatusCleanup:
    """Тесты очистки по статусу."""

    @patch("app.gateways.notion_review.fetch_all_reviews")
    @patch("app.gateways.notion_review.bulk_update_status")
    def test_cleanup_by_status_resolved(self, mock_bulk_update, mock_fetch):
        """Тест очистки resolved записей."""
        # fetch_all_reviews с фильтром должен вернуть только resolved записи
        mock_fetch.return_value = [
            {"id": "resolved-1", "status": "resolved", "text": "задача 1"},
            {"id": "resolved-2", "status": "resolved", "text": "задача 2"},
        ]
        mock_bulk_update.return_value = {"updated": 2, "errors": 0}

        stats = cleanup_by_status("resolved", dry_run=False)

        assert stats.scanned == 2  # Только resolved записи благодаря фильтру
        assert stats.archived == 2
        assert stats.errors == 0

        # Проверяем что bulk_update вызывался с правильными ID
        # Проверяем что bulk_update вызывался с правильными ID
        call_args = mock_bulk_update.call_args[0]
        assert set(call_args[0]) == {"resolved-1", "resolved-2"}
        assert call_args[1] == "archived"

    @patch("app.gateways.notion_review.fetch_all_reviews")
    def test_cleanup_by_status_dry_run(self, mock_fetch):
        """Тест dry-run режима очистки по статусу."""
        mock_fetch.return_value = [
            {"id": "dropped-1", "status": "dropped", "text": "задача 1"},
        ]

        stats = cleanup_by_status("dropped", dry_run=True)

        assert stats.scanned == 1
        assert stats.archived == 1  # В dry-run считается как архивированные
        assert stats.errors == 0

    @patch("app.gateways.notion_review.fetch_all_reviews")
    def test_cleanup_no_matching_status(self, mock_fetch):
        """Тест очистки когда нет записей с целевым статусом."""
        mock_fetch.return_value = []  # Пустой результат

        stats = cleanup_by_status("resolved", dry_run=True)

        assert stats.scanned == 0
        assert stats.archived == 0
        assert stats.errors == 0


class TestComprehensiveCleanup:
    """Тесты комплексной очистки."""

    @patch("app.core.review_cleanup.auto_archive_old_reviews")
    @patch("app.core.review_cleanup.find_duplicate_reviews")
    def test_comprehensive_cleanup_all_operations(self, mock_find_dups, mock_archive):
        """Тест комплексной очистки со всеми операциями."""
        # Мокаем результаты операций
        archive_stats = CleanupStats()
        archive_stats.scanned = 10
        archive_stats.archived = 3

        dup_stats = CleanupStats()
        dup_stats.scanned = 15
        dup_stats.duplicates_found = 2

        mock_archive.return_value = archive_stats
        mock_find_dups.return_value = dup_stats

        # Выполняем комплексную очистку
        results = comprehensive_cleanup(archive_days=7, similarity_threshold=0.9, dry_run=True)

        # Проверяем что обе операции выполнились
        assert "archive" in results
        assert "duplicates" in results

        # Проверяем вызовы функций
        mock_archive.assert_called_once_with(7, True)
        mock_find_dups.assert_called_once_with(0.9)

    def test_comprehensive_cleanup_error_handling(self):
        """Тест обработки ошибок в комплексной очистке."""
        with patch("app.core.review_cleanup.auto_archive_old_reviews") as mock_archive:
            mock_archive.side_effect = Exception("Archive error")

            # Операция должна продолжиться даже при ошибке в одной части
            results = comprehensive_cleanup(dry_run=True)

            # Результаты должны быть возвращены даже при ошибке
            assert isinstance(results, dict)


class TestSimilarityAlgorithms:
    """Тесты алгоритмов похожести."""

    def test_sequence_similarity(self):
        """Тест sequence similarity."""
        # Тестируем разные уровни похожести
        test_cases = [
            ("подготовить отчет", "подготовить отчет", 1.0),  # Идентичные
            ("подготовить отчет", "подготовить отчёт", 0.6),  # Опечатка
            ("подготовить отчет", "подготовить презентацию", 0.6),  # Частично похожие
            ("подготовить отчет", "проверить данные", 0.2),  # Разные
        ]

        for text1, text2, expected_min in test_cases:
            similarity = calculate_text_similarity(text1, text2)
            assert (
                similarity >= expected_min - 0.1
            ), f"Similarity too low for '{text1}' vs '{text2}': {similarity}"

    def test_jaccard_similarity_component(self):
        """Тест Jaccard компонента в алгоритме."""
        # Тексты с общими токенами
        sim1 = calculate_text_similarity("подготовить отчет данные", "проверить отчет данные")
        sim2 = calculate_text_similarity("подготовить отчет", "проверить презентацию")

        # Первая пара должна быть более похожей (больше общих токенов)
        assert sim1 > sim2

    def test_edge_cases_similarity(self):
        """Тест граничных случаев для similarity."""
        # Очень короткие тексты
        sim = calculate_text_similarity("да", "нет")
        assert 0.0 <= sim <= 1.0

        # Очень длинные тексты
        long_text1 = "подготовить отчет " * 100
        long_text2 = "подготовить отчёт " * 100
        sim = calculate_text_similarity(long_text1, long_text2)
        assert sim > 0.1  # Алгоритм может давать низкие значения для повторяющихся паттернов


class TestIntegrationScenarios:
    """Тесты интеграционных сценариев."""

    @patch("app.gateways.notion_review.fetch_all_reviews")
    @patch("app.gateways.notion_review.bulk_update_status")
    def test_mixed_age_and_status_records(self, mock_bulk_update, mock_fetch):
        """Тест смешанных записей разного возраста и статуса."""
        now = datetime.now(UTC)
        old_date = (now - timedelta(days=20)).isoformat()
        recent_date = (now - timedelta(days=5)).isoformat()

        mock_fetch.return_value = [
            {"id": "old-resolved", "status": "resolved", "last_edited_time": old_date},
            {"id": "old-dropped", "status": "dropped", "last_edited_time": old_date},
            {"id": "recent-resolved", "status": "resolved", "last_edited_time": recent_date},
            {"id": "old-pending", "status": "pending", "last_edited_time": old_date},
        ]
        mock_bulk_update.return_value = {"updated": 2, "errors": 0}

        stats = auto_archive_old_reviews(days_threshold=14, dry_run=False)

        # Должны архивироваться только старые закрытые записи
        assert stats.scanned == 4
        assert stats.archived == 2
        assert stats.old_resolved == 1
        assert stats.old_dropped == 1

    @patch("app.gateways.notion_review.fetch_all_reviews")
    def test_large_queue_performance(self, mock_fetch):
        """Тест производительности на большой очереди."""
        # Создаем большой набор записей
        large_queue = [
            {"id": f"review-{i}", "text": f"задача {i}", "status": "pending"} for i in range(200)
        ]
        mock_fetch.return_value = large_queue

        stats = find_duplicate_reviews(similarity_threshold=0.85, max_checks=100)

        # Должно обработать только первые 100 записей из-за лимита
        assert stats.scanned == 200  # scanned показывает все загруженные записи
        assert stats.processing_time_s < 10  # Должно быть достаточно быстро

    def test_real_world_duplicate_scenarios(self):
        """Тест реальных сценариев дубликатов."""
        # Типичные дубликаты от LLM
        llm_duplicates = [
            ("подготовить отчет по продажам к пятнице", "подготовить отчёт по продажам к пятнице"),
            ("Саша сделает презентацию", "Саша подготовит презентацию"),
            ("проверить интеграцию с API", "проверить интеграцию API"),
        ]

        for text1, text2 in llm_duplicates:
            similarity = calculate_text_similarity(text1, text2)
            assert (
                similarity > 0.5
            ), f"LLM duplicates should be similar: '{text1}' vs '{text2}' = {similarity}"


class TestErrorHandling:
    """Тесты обработки ошибок."""

    @patch("app.gateways.notion_review.fetch_all_reviews")
    def test_fetch_error_handling(self, mock_fetch):
        """Тест обработки ошибок при получении данных."""
        mock_fetch.side_effect = Exception("Fetch error")

        stats = auto_archive_old_reviews(dry_run=True)

        # Операция должна завершиться с ошибкой но не упасть
        assert stats.errors >= 1
        assert stats.processing_time_s > 0

    @patch("app.gateways.notion_review.fetch_all_reviews")
    @patch("app.gateways.notion_review.bulk_update_status")
    def test_bulk_update_error_handling(self, mock_bulk_update, mock_fetch):
        """Тест обработки ошибок при массовом обновлении."""
        old_date = (datetime.now(UTC) - timedelta(days=20)).isoformat()

        mock_fetch.return_value = [
            {"id": "review-1", "status": "resolved", "last_edited_time": old_date}
        ]
        mock_bulk_update.side_effect = Exception("Update error")

        stats = auto_archive_old_reviews(dry_run=False)

        assert stats.scanned == 1
        assert stats.errors == 1
        assert stats.archived == 0  # Не удалось архивировать из-за ошибки

    def test_invalid_date_format_handling(self):
        """Тест обработки невалидных форматов дат."""
        with patch("app.core.review_cleanup.fetch_all_reviews") as mock_fetch:
            mock_fetch.return_value = [
                {"id": "review-1", "status": "resolved", "last_edited_time": "invalid-date-format"}
            ]

            stats = auto_archive_old_reviews(dry_run=True)

            # Запись с невалидной датой должна быть пропущена без ошибки
            assert stats.scanned == 1
            assert stats.archived == 0  # Пропущена из-за невалидной даты


class TestPerformanceOptimizations:
    """Тесты оптимизаций производительности."""

    def test_fingerprint_grouping_efficiency(self):
        """Тест эффективности группировки по fingerprints."""
        # Создаем тексты с одинаковыми fingerprints
        similar_texts = [
            "подготовить отчет",
            "Подготовить ОТЧЕТ!",
            "подготовить... отчет",
        ]

        fingerprints = [text_fingerprint(text) for text in similar_texts]

        # Все должны иметь одинаковый fingerprint
        assert len(set(fingerprints)) == 1

        # Разные тексты должны иметь разные fingerprints
        different_fp = text_fingerprint("проверить данные")
        assert different_fp != fingerprints[0]

    def test_similarity_performance_bounds(self):
        """Тест границ производительности similarity."""
        import time

        # Тестируем на текстах разной длины
        short_text = "подготовить отчет"
        long_text = "подготовить детальный отчет по продажам с анализом данных " * 10

        # Короткие тексты должны обрабатываться быстро
        start = time.perf_counter()
        sim1 = calculate_text_similarity(short_text, short_text)
        short_time = time.perf_counter() - start

        # Длинные тексты могут занимать больше времени, но не критично
        start = time.perf_counter()
        sim2 = calculate_text_similarity(long_text, long_text)
        long_time = time.perf_counter() - start

        assert sim1 == 1.0
        assert sim2 == 1.0
        assert short_time < 0.01  # Короткие тексты < 10ms
        assert long_time < 0.1  # Длинные тексты < 100ms
